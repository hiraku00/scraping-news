# ニューススクレイピングとツイート投稿ツール

このリポジトリには、NHKとテレビ東京のニュースサイトから情報をスクレイピングし、その結果をX（旧Twitter）に投稿するためのPythonスクリプトが含まれています。スクリプトは、指定された日付のニュース番組情報を取得し、それをXにスレッド形式で投稿します。

## 概要

このツールは以下の4つの主要なスクリプトで構成されています。

1. **`scraping-news.py`**: NHKとテレビ東京のウェブサイトからニュース番組情報をスクレイピングします。
2. **`open-url.py`**: スクレイピング結果のURLを自動的にブラウザで開きます。
3. **`split-text.py`**: スクレイピング結果をツイート用に分割します。
4. **`tweet.py`**: スクレイピングされた情報を基に、Xにツイートを投稿します。

## スクリプトの詳細

### `scraping-news.py`

このスクリプトは、NHKとテレビ東京のウェブサイトから指定された日付のニュース番組情報を収集します。

#### 機能

- **設定ファイルの利用**: `ini`ディレクトリ内の設定ファイル（`nhk_config.ini`, `tvtokyo_config.ini`）に基づいてスクレイピング対象の番組を定義します。
- **動的なウェブページスクレイピング**: SeleniumとChrome WebDriverを利用して、JavaScriptで動的に生成されるウェブページから情報を抽出します。
- **マルチプロセス**: 複数の番組情報を並行してスクレイピングすることで、処理時間を短縮します。
- **ログ出力**: 処理の進行状況やエラーを詳細にログに記録します。
- **詳細な番組情報抽出**: 各番組のエピソードタイトル、URL、放送時間を抽出します。
- **時間順のソート**: スクレイピングした番組情報を時間順にソートして出力します。

#### 依存ライブラリ

- `requests`: HTTPリクエストを送信します。
- `selenium`: ウェブブラウザの自動操作に利用します。
- `webdriver_manager`: ChromeDriverの管理に利用します。
- `datetime`: 日付と時間の操作に利用します。
- `os`: OS関連の操作に利用します。
- `sys`: システム関連の操作に利用します。
- `time`: 時間関連の操作に利用します。
- `multiprocessing`: 並列処理に利用します。
- `logging`: ログ出力に利用します。
- `configparser`: 設定ファイルの解析に利用します。
- `re`: 正規表現操作に利用します。

#### 使い方

1. `ini`ディレクトリに設定ファイルを作成します（例：`nhk_config.ini`, `tvtokyo_config.ini`）。
    - `nhk_config.ini`の例:
        ```ini
        [program_1]
        name = BSスペシャル
        url = https://www.nhk.jp/p/bssp/ts/X7WJ4Z9R3G/episode/
        channel = NHK BS
        ```
    - `tvtokyo_config.ini`の例:
        ```ini
        [program_1]
        name = WBS
        url = https://txbiz.tv-tokyo.co.jp/wbs/feature
        time = 22:00~22:58
        ```

2. 以下のコマンドでスクリプトを実行します。
    ```bash
    python scraping-news.py <取得したい日付(例:20250125)>
    ```

3. スクレイピング結果は `output` ディレクトリに日付ごとのテキストファイルとして保存されます。

### `open-url.py`

このスクリプトは、`scraping-news.py`によって生成されたテキストファイルからURLを抽出し、自動的にブラウザで開きます。

#### 機能

- **設定ファイルの利用**: `ini`ディレクトリ内の設定ファイル（`nhk_config.ini`, `tvtokyo_config.ini`）に基づいてURLを抽出します。
- **URLの自動開封**: 抽出したURLを自動的にブラウザで開きます。

#### 使い方

1. 以下のコマンドでスクリプトを実行します。
    ```bash
    python open-url.py <日付(例:20250125)>
    ```

### `split-text.py`

このスクリプトは、`scraping-news.py`によって生成されたテキストファイルをツイート用に分割します。

#### 機能

- **文字数制限の考慮**: ツイートの文字数制限（280文字）を考慮して、テキストを分割します。
- **URLの文字数計算**: URLを11.5文字として計算し、ツイートの文字数制限を超えないように調整します。

#### 使い方

1. 以下のコマンドでスクリプトを実行します。
    ```bash
    python split-text.py <日付(例:20250125)>
    ```

### `tweet.py`

このスクリプトは、`scraping-news.py`によって生成されたテキストファイルを読み込み、その内容をX（旧Twitter）に投稿します。

#### 機能

- **X APIの利用**: `tweepy`ライブラリを使用してX APIにアクセスし、ツイートを投稿します。
- **環境変数**: APIキーなどの認証情報は環境変数から読み込みます。
- **スレッド形式での投稿**: スクレイピング結果をスレッド形式で投稿します。
- **エラーハンドリング**: レート制限やHTTPエラーを適切に処理します。
- **文字数制限**: ツイートが文字数制限を超えないようにチェックします。

#### 依存ライブラリ

- `tweepy`: X APIクライアントとして利用します。
- `time`: 時間関連の操作に利用します。
- `sys`: システム関連の操作に利用します。
- `os`: OS関連の操作に利用します。
- `dotenv`: 環境変数の管理に利用します。
- `re`: 正規表現操作に利用します。

#### 使い方

1. `.env`ファイルを作成し、以下のX APIキーを設定します。
    ```env
    API_KEY=<APIキー>
    API_SECRET=<APIシークレット>
    ACCESS_TOKEN=<アクセストークン>
    ACCESS_SECRET=<アクセスシークレット>
    BEARER_TOKEN=<ベアラートークン>
    ```

2. 以下のコマンドでスクリプトを実行します。
    ```bash
    python tweet.py <投稿したい日付(例:20250125)>
    ```

## 注意事項

- このツールを使用する前に、各ウェブサイトの利用規約を必ず確認してください。
- スクレイピングはサイトに負荷をかける可能性があるため、頻繁なアクセスは避けてください。
- X APIの利用制限を守り、過度な投稿を避けてください。
- 環境変数は適切に管理し、漏洩しないように注意してください。
- `chromedriver` は事前にインストールし、パスを通すか、`webdriver_manager`を利用してインストールする必要があります。
